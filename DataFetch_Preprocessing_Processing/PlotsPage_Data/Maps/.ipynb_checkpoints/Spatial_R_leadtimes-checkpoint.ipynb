{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d81c76ca-01ef-4674-9995-c5b0303f36fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d04af7-83b0-40b3-b812-bb6846afc827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess function\n",
    "def preprocess(ds):\n",
    "    if \"t2m\" in ds:\n",
    "        ds[\"t2m\"] = ds[\"t2m\"] - 273.15\n",
    "        ds[\"t2m\"].attrs[\"units\"] = \"Celsius\"\n",
    "    if \"msl\" in ds:\n",
    "        ds[\"msl\"] = ds[\"msl\"] / 100.0\n",
    "        ds[\"msl\"].attrs[\"units\"] = \"hPa\"\n",
    "    if \"tp\" in ds:\n",
    "        ds = ds.drop_vars(\"tp\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e66ff-d829-485d-aa00-19ba9c92acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marsfc - Compute the Pearson Correlation Coefficient per lead time per grid cell across all 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d141620-f416-4e92-a247-cfb9fac654cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_files = sorted([\n",
    "    \"../../Surface Variables/20240101/20240101_marsfc_sv_q.nc\", \"../../Surface Variables/20240201/20240201_marsfc_sv_q.nc\", \n",
    "    \"../../Surface Variables/20240301/20240301_marsfc_sv_q.nc\", \"../../Surface Variables/20240401/20240401_marsfc_sv_q.nc\",\n",
    "    \"../../Surface Variables/20240501/20240501_marsfc_sv_q.nc\", \"../../Surface Variables/20240601/20240601_marsfc_sv_q.nc\", \n",
    "    \"../../Surface Variables/20240701/20240701_marsfc_sv_q.nc\", \"../../Surface Variables/20240801/20240801_marsfc_sv_q.nc\",\n",
    "    \"../../Surface Variables/20240901/20240901_marsfc_sv_q.nc\", \"../../Surface Variables/20241001/20241001_marsfc_sv_q.nc\", \n",
    "    \"../../Surface Variables/20241101/20241101_marsfc_sv_q.nc\", \"../../Surface Variables/20241201/20241201_marsfc_sv_q.nc\"\n",
    "])\n",
    "\n",
    "truth_files = sorted([\n",
    "    \"../../Surface Variables/20240101/20240101_era5_fc_sv_q.nc\", \"../../Surface Variables/20240201/20240201_era5_fc_sv_q.nc\", \n",
    "    \"../../Surface Variables/20240301/20240301_era5_fc_sv_q.nc\", \"../../Surface Variables/20240401/20240401_era5_fc_sv_q.nc\",\n",
    "    \"../../Surface Variables/20240501/20240501_era5_fc_sv_q.nc\", \"../../Surface Variables/20240601/20240601_era5_fc_sv_q.nc\", \n",
    "    \"../../Surface Variables/20240701/20240701_era5_fc_sv_q.nc\", \"../../Surface Variables/20240801/20240801_era5_fc_sv_q.nc\",\n",
    "    \"../../Surface Variables/20240901/20240901_era5_fc_sv_q.nc\", \"../../Surface Variables/20241001/20241001_era5_fc_sv_q.nc\", \n",
    "    \"../../Surface Variables/20241101/20241101_era5_fc_sv_q.nc\", \"../../Surface Variables/20241201/20241201_era5_fc_sv_q.nc\"\n",
    "])\n",
    "\n",
    "variables = ['t2m', 'q', 'u10', 'v10', 'msl']\n",
    "results = {}\n",
    "\n",
    "def daskpreprocess(ds):\n",
    "    return ds.chunk({'time': 41, 'latitude': 64, 'longitude': 128})\n",
    "\n",
    "\n",
    "# Vectorized pearson function\n",
    "def pearsonr_ufunc(x, y):\n",
    "    return np.corrcoef(x, y)[0, 1] if np.all(np.isfinite(x)) and np.all(np.isfinite(y)) else np.nan\n",
    "\n",
    "for var in variables:\n",
    "    print(f\"Starting for {var}\")\n",
    "    fc_stack = []\n",
    "    truth_stack = []\n",
    "\n",
    "    for f_path, t_path in zip(forecast_files, truth_files):\n",
    "        print(f\"Loading {f_path}\")\n",
    "        ds_f = preprocess(xr.open_dataset(f_path))\n",
    "        ds_t = preprocess(xr.open_dataset(t_path))\n",
    "\n",
    "        ds_t = ds_t.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "         # assign numbers for timesteps instead of datetime stamps\n",
    "        ds_f = ds_f.assign_coords(time=np.arange(len(ds_f.time)).astype(\"float64\"))\n",
    "        ds_t = ds_t.assign_coords(time=np.arange(len(ds_t.time)).astype(\"float64\"))\n",
    "\n",
    "        # Apply dask chunking\n",
    "        ds_f = daskpreprocess(ds_f)\n",
    "        ds_t = daskpreprocess(ds_t)\n",
    "\n",
    "        forecast, truth = ds_f[var], ds_t[var]\n",
    "        forecast, truth = xr.align(forecast, truth)\n",
    "\n",
    "        fc_stack.append(forecast)\n",
    "        truth_stack.append(truth)\n",
    "        print(\"Stacked\")\n",
    "\n",
    "    \n",
    "    forecast = xr.concat(fc_stack, dim='month')\n",
    "    truth = xr.concat(truth_stack, dim='month')\n",
    "    print(\"joined all Stacked together\")\n",
    "\n",
    "    print(f\"  computing correlation for {var}\")\n",
    "\n",
    "    # Rechunk so 'month' is in one block\n",
    "    forecast = forecast.chunk({'month': -1})\n",
    "    truth = truth.chunk({'month': -1})\n",
    "    \n",
    "    # Compute correlation across 'month' dimension for each time/lat/lon\n",
    "    corr = xr.apply_ufunc(\n",
    "        pearsonr_ufunc,\n",
    "        forecast,\n",
    "        truth,\n",
    "        input_core_dims=[['month'], ['month']],\n",
    "        vectorize=True,\n",
    "        dask='parallelized',\n",
    "        output_dtypes=[float],\n",
    "    )\n",
    "    print(\"computed correlation\")\n",
    "\n",
    "    # Assign coordinates for clarity\n",
    "    corr = corr.assign_coords({\n",
    "    \"time\": forecast.time,\n",
    "    \"latitude\": forecast.latitude,\n",
    "    \"longitude\": forecast.longitude\n",
    "    })\n",
    "\n",
    "    results[var] = corr\n",
    "    print(f\"âœ… done with {var}\")\n",
    "\n",
    "# Convert dictionary to dataset\n",
    "ds_out = xr.Dataset(results)\n",
    "print(\"results turned into Dataset\")\n",
    "# ds_out.load()\n",
    "#print(\"ðŸ’¾ Saving to NetCDF...\")\n",
    "#ds_out.to_netcdf('Global_marsfc_CC_MAP_leadtimes.nc')\n",
    "#print(\"âœ… Correlation dataset saved as 'Global_marsfc_CC_MAP_leadtimes.nc'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f438f50-765d-4dc7-80b3-1b112e2106d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save variables individually to avoid loading everything into memory\n",
    "for var in ds_out.data_vars:\n",
    "    print(f\"Starting for {var}\")\n",
    "    # compute() and load() load to the memory\n",
    "    ds_out[var] = ds_out[var].compute()\n",
    "    print(f\"Loaded {var} to memory\")\n",
    "print(f\"Start saving to netcdf\")\n",
    "ds_out.to_netcdf(\"Global_marsfc_CC_MAP_leadtimes.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece4a6d-3c88-474f-860a-d625ef1e31d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb3ba45-cd55-4c0b-a30e-521f750f504d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting for t2m\n",
      "Loading ../../Surface Variables/20240301/20240301_marsai_sv_q.nc\n",
      "Stacked\n",
      "Loading ../../Surface Variables/20240401/20240401_marsai_sv_q.nc\n",
      "Stacked\n",
      "Loading ../../Surface Variables/20240501/20240501_marsai_sv_q.nc\n",
      "Stacked\n",
      "Loading ../../Surface Variables/20240601/20240601_marsai_sv_q.nc\n",
      "Stacked\n",
      "Loading ../../Surface Variables/20240701/20240701_marsai_sv_q.nc\n",
      "Stacked\n",
      "Loading ../../Surface Variables/20240801/20240801_marsai_sv_q.nc\n",
      "Stacked\n",
      "Loading ../../Surface Variables/20240901/20240901_marsai_sv_q.nc\n",
      "Stacked\n",
      "Loading ../../Surface Variables/20241001/20241001_marsai_sv_q.nc\n",
      "Stacked\n",
      "Loading ../../Surface Variables/20241101/20241101_marsai_sv_q.nc\n",
      "Stacked\n",
      "Loading ../../Surface Variables/20241201/20241201_marsai_sv_q.nc\n",
      "Stacked\n",
      "joined all Stacked together\n",
      "  computing correlation for t2m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 69\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  computing correlation for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;66;03m# Rechunk so 'month' is in one block\u001b[39;00m\n\u001b[1;32m     65\u001b[0m  \u001b[38;5;66;03m# forecast = forecast.chunk({'month': -1})\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#  truth = truth.chunk({'month': -1})\u001b[39;00m\n\u001b[1;32m     67\u001b[0m   \n\u001b[1;32m     68\u001b[0m   \u001b[38;5;66;03m# Compute correlation across 'month' dimension for each time/lat/lon\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m   corr \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mapply_ufunc(\n\u001b[1;32m     70\u001b[0m       pearsonr_ufunc,\n\u001b[1;32m     71\u001b[0m       forecast,\n\u001b[1;32m     72\u001b[0m       truth,\n\u001b[1;32m     73\u001b[0m       input_core_dims\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[1;32m     74\u001b[0m       vectorize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m#  dask='parallelized',\u001b[39;00m\n\u001b[1;32m     76\u001b[0m       output_dtypes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[1;32m     77\u001b[0m   )\n\u001b[1;32m     78\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomputed correlation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     80\u001b[0m   \u001b[38;5;66;03m# Assign coordinates for clarity\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/weatherdata/lib/python3.12/site-packages/xarray/core/computation.py:1265\u001b[0m, in \u001b[0;36mapply_ufunc\u001b[0;34m(func, input_core_dims, output_core_dims, exclude_dims, vectorize, join, dataset_join, dataset_fill_value, keep_attrs, kwargs, dask, output_dtypes, output_sizes, meta, dask_gufunc_kwargs, on_missing_core_dim, *args)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;66;03m# feed DataArray apply_variable_ufunc through apply_dataarray_vfunc\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(a, DataArray) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m-> 1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_dataarray_vfunc(\n\u001b[1;32m   1266\u001b[0m         variables_vfunc,\n\u001b[1;32m   1267\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m   1268\u001b[0m         signature\u001b[38;5;241m=\u001b[39msignature,\n\u001b[1;32m   1269\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m   1270\u001b[0m         exclude_dims\u001b[38;5;241m=\u001b[39mexclude_dims,\n\u001b[1;32m   1271\u001b[0m         keep_attrs\u001b[38;5;241m=\u001b[39mkeep_attrs,\n\u001b[1;32m   1272\u001b[0m     )\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;66;03m# feed Variables directly through apply_variable_ufunc\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(a, Variable) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/weatherdata/lib/python3.12/site-packages/xarray/core/computation.py:307\u001b[0m, in \u001b[0;36mapply_dataarray_vfunc\u001b[0;34m(func, signature, join, exclude_dims, keep_attrs, *args)\u001b[0m\n\u001b[1;32m    302\u001b[0m result_coords, result_indexes \u001b[38;5;241m=\u001b[39m build_output_coords_and_indexes(\n\u001b[1;32m    303\u001b[0m     args, signature, exclude_dims, combine_attrs\u001b[38;5;241m=\u001b[39mkeep_attrs\n\u001b[1;32m    304\u001b[0m )\n\u001b[1;32m    306\u001b[0m data_vars \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(a, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m--> 307\u001b[0m result_var \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39mdata_vars)\n\u001b[1;32m    309\u001b[0m out: \u001b[38;5;28mtuple\u001b[39m[DataArray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m|\u001b[39m DataArray\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/weatherdata/lib/python3.12/site-packages/xarray/core/computation.py:818\u001b[0m, in \u001b[0;36mapply_variable_ufunc\u001b[0;34m(func, signature, exclude_dims, dask, output_dtypes, vectorize, keep_attrs, dask_gufunc_kwargs, *args)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vectorize:\n\u001b[1;32m    814\u001b[0m         func \u001b[38;5;241m=\u001b[39m _vectorize(\n\u001b[1;32m    815\u001b[0m             func, signature, output_dtypes\u001b[38;5;241m=\u001b[39moutput_dtypes, exclude_dims\u001b[38;5;241m=\u001b[39mexclude_dims\n\u001b[1;32m    816\u001b[0m         )\n\u001b[0;32m--> 818\u001b[0m result_data \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39minput_data)\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    821\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m (result_data,)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/weatherdata/lib/python3.12/site-packages/numpy/lib/function_base.py:2372\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_stage_2(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 2372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_as_normal(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/weatherdata/lib/python3.12/site-packages/numpy/lib/function_base.py:2365\u001b[0m, in \u001b[0;36mvectorize._call_as_normal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m     vargs \u001b[38;5;241m=\u001b[39m [args[_i] \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m inds]\n\u001b[1;32m   2363\u001b[0m     vargs\u001b[38;5;241m.\u001b[39mextend([kwargs[_n] \u001b[38;5;28;01mfor\u001b[39;00m _n \u001b[38;5;129;01min\u001b[39;00m names])\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize_call(func\u001b[38;5;241m=\u001b[39mfunc, args\u001b[38;5;241m=\u001b[39mvargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/weatherdata/lib/python3.12/site-packages/numpy/lib/function_base.py:2446\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2444\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Vectorized call to `func` over positional `args`.\"\"\"\u001b[39;00m\n\u001b[1;32m   2445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2446\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize_call_with_signature(func, args)\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m   2448\u001b[0m     res \u001b[38;5;241m=\u001b[39m func()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/weatherdata/lib/python3.12/site-packages/numpy/lib/function_base.py:2486\u001b[0m, in \u001b[0;36mvectorize._vectorize_call_with_signature\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2483\u001b[0m nout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output_core_dims)\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndindex(\u001b[38;5;241m*\u001b[39mbroadcast_shape):\n\u001b[0;32m-> 2486\u001b[0m     results \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39m(arg[index] \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[1;32m   2488\u001b[0m     n_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nout \u001b[38;5;241m!=\u001b[39m n_results:\n",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m, in \u001b[0;36mpearsonr_ufunc\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpearsonr_ufunc\u001b[39m(x, y):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcorrcoef(x, y)[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misfinite(x)) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misfinite(y)) \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[0;32m/opt/anaconda3/envs/weatherdata/lib/python3.12/site-packages/numpy/lib/function_base.py:2889\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[1;32m   2885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;129;01mor\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n\u001b[1;32m   2886\u001b[0m     \u001b[38;5;66;03m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[1;32m   2887\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias and ddof have no effect and are deprecated\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   2888\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m-> 2889\u001b[0m c \u001b[38;5;241m=\u001b[39m cov(x, y, rowvar, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2891\u001b[0m     d \u001b[38;5;241m=\u001b[39m diag(c)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/weatherdata/lib/python3.12/site-packages/numpy/lib/function_base.py:2680\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2680\u001b[0m     y \u001b[38;5;241m=\u001b[39m array(y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, ndmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rowvar \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2682\u001b[0m         y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "forecast_files = sorted([\n",
    "   # \"../../Surface Variables/20240101/20240101_marsai_sv_q.nc\", \"../../Surface Variables/20240201/20240201_marsai_sv_q.nc\", \n",
    "    \"../../Surface Variables/20240301/20240301_marsai_sv_q.nc\", \"../../Surface Variables/20240401/20240401_marsai_sv_q.nc\",\n",
    "    \"../../Surface Variables/20240501/20240501_marsai_sv_q.nc\", \"../../Surface Variables/20240601/20240601_marsai_sv_q.nc\", \n",
    "    \"../../Surface Variables/20240701/20240701_marsai_sv_q.nc\", \"../../Surface Variables/20240801/20240801_marsai_sv_q.nc\",\n",
    "    \"../../Surface Variables/20240901/20240901_marsai_sv_q.nc\", \"../../Surface Variables/20241001/20241001_marsai_sv_q.nc\", \n",
    "    \"../../Surface Variables/20241101/20241101_marsai_sv_q.nc\", \"../../Surface Variables/20241201/20241201_marsai_sv_q.nc\"\n",
    "])\n",
    "\n",
    "truth_files = sorted([\n",
    " #   \"../../Surface Variables/20240101/20240101_era5_gcai_sv_q.nc\", \"../../Surface Variables/20240201/20240201_era5_gcai_sv_q.nc\", \n",
    "    \"../../Surface Variables/20240301/20240301_era5_gcai_sv_q.nc\", \"../../Surface Variables/20240401/20240401_era5_gcai_sv_q.nc\",\n",
    "    \"../../Surface Variables/20240501/20240501_era5_gcai_sv_q.nc\", \"../../Surface Variables/20240601/20240601_era5_gcai_sv_q.nc\", \n",
    "    \"../../Surface Variables/20240701/20240701_era5_gcai_sv_q.nc\", \"../../Surface Variables/20240801/20240801_era5_gcai_sv_q.nc\",\n",
    "    \"../../Surface Variables/20240901/20240901_era5_gcai_sv_q.nc\", \"../../Surface Variables/20241001/20241001_era5_gcai_sv_q.nc\", \n",
    "    \"../../Surface Variables/20241101/20241101_era5_gcai_sv_q.nc\", \"../../Surface Variables/20241201/20241201_era5_gcai_sv_q.nc\"\n",
    "])\n",
    "\n",
    "variables = ['t2m', 'q', 'u10', 'v10', 'msl']\n",
    "results = {}\n",
    "\n",
    "#def daskpreprocess(ds):\n",
    "#    return ds.chunk({'time': 41, 'latitude': 64, 'longitude': 128})\n",
    "\n",
    "\n",
    "# Vectorized pearson function\n",
    "def pearsonr_ufunc(x, y):\n",
    "    return np.corrcoef(x, y)[0, 1] if np.all(np.isfinite(x)) and np.all(np.isfinite(y)) else np.nan\n",
    "\n",
    "for var in variables:\n",
    "    print(f\"Starting for {var}\")\n",
    "    fc_stack = []\n",
    "    truth_stack = []\n",
    "\n",
    "    for f_path, t_path in zip(forecast_files, truth_files):\n",
    "        print(f\"Loading {f_path}\")\n",
    "        ds_f = preprocess(xr.open_dataset(f_path))\n",
    "        ds_t = preprocess(xr.open_dataset(t_path))\n",
    "\n",
    "        ds_t = ds_t.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "         # assign numbers for timesteps instead of datetime stamps\n",
    "        ds_f = ds_f.assign_coords(time=np.arange(len(ds_f.time)).astype(\"float64\"))\n",
    "        ds_t = ds_t.assign_coords(time=np.arange(len(ds_t.time)).astype(\"float64\"))\n",
    "\n",
    "        # Apply dask chunking\n",
    "      #  ds_f = daskpreprocess(ds_f)\n",
    "      #  ds_t = daskpreprocess(ds_t)\n",
    "\n",
    "        forecast, truth = ds_f[var], ds_t[var]\n",
    "        forecast, truth = xr.align(forecast, truth)\n",
    "\n",
    "        fc_stack.append(forecast)\n",
    "        truth_stack.append(truth)\n",
    "        print(\"Stacked\")\n",
    "\n",
    "    \n",
    "    forecast = xr.concat(fc_stack, dim='month')\n",
    "    truth = xr.concat(truth_stack, dim='month')\n",
    "    print(\"joined all Stacked together\")\n",
    "\n",
    "    print(f\"  computing correlation for {var}\")\n",
    "\n",
    "    # Rechunk so 'month' is in one block\n",
    "   # forecast = forecast.chunk({'month': -1})\n",
    "  #  truth = truth.chunk({'month': -1})\n",
    "    \n",
    "    # Compute correlation across 'month' dimension for each time/lat/lon\n",
    "    corr = xr.apply_ufunc(\n",
    "        pearsonr_ufunc,\n",
    "        forecast,\n",
    "        truth,\n",
    "        input_core_dims=[['month'], ['month']],\n",
    "        vectorize=True,\n",
    "      #  dask='parallelized',\n",
    "        output_dtypes=[float],\n",
    "    )\n",
    "    print(\"computed correlation\")\n",
    "\n",
    "    # Assign coordinates for clarity\n",
    "    corr = corr.assign_coords({\n",
    "    \"time\": forecast.time,\n",
    "    \"latitude\": forecast.latitude,\n",
    "    \"longitude\": forecast.longitude\n",
    "    })\n",
    "\n",
    "    results[var] = corr\n",
    "    print(f\"âœ… done with {var}\")\n",
    "\n",
    "# Convert dictionary to dataset\n",
    "ds_out = xr.Dataset(results)\n",
    "print(\"results turned into Dataset\")\n",
    "# ds_out.load()\n",
    "print(\"ðŸ’¾ Saving to NetCDF...\")\n",
    "ds_out.to_netcdf('Global_marsai_CC_MAP_leadtimes.nc')\n",
    "#print(\"âœ… Correlation dataset saved as 'Global_marsfc_CC_MAP_leadtimes.nc'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1736dbd-f611-4df7-832d-7449ad91dbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting for t2m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save variables individually to avoid loading everything into memory\n",
    "for var in ds_out.data_vars:\n",
    "    print(f\"Starting for {var}\")\n",
    "    # compute() and load() load to the memory\n",
    "    ds_out[var] = ds_out[var].compute()\n",
    "    print(f\"Loaded {var} to memory\")\n",
    "print(f\"Start saving to netcdf\")\n",
    "ds_out.to_netcdf(\"Global_marsai_CC_MAP_leadtimes.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a94186-20bc-47fd-a085-2b52caafc2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds_out.to_netcdf(\"Global_marsai_CC_MAP_leadtimes.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e491ab9-babd-4086-947c-9e0c257f542f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
