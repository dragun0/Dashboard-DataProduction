{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d63ad6-76fb-4154-befb-12cc49453f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy.stats import pearsonr\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8956687-c072-4dd0-b38b-b0d0f8bf42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pearson correlation coefficient (R) averaged over space (lat and lon) and months for each lead time (i.e. timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759708fa-547f-45bc-a98f-a651d3dc0f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to subset to subpolar and polar regions\n",
    "def subset_polar_regions(ds):\n",
    "    return ds.where((ds.latitude >= 60) | (ds.latitude <= -60), drop=True)\n",
    "\n",
    "def subset_northern_temperate(ds):\n",
    "    \"\"\"Subset dataset to the Northern Temperate Zone: 35°N to 60°N.\"\"\"\n",
    "    return ds.where((ds.latitude >= 35) & (ds.latitude <= 60), drop=True)\n",
    "\n",
    "def subset_southern_temperate(ds):\n",
    "    \"\"\"Subset dataset to the Northern Temperate Zone: 35°N to 60°N.\"\"\"\n",
    "    return ds.where((ds.latitude <= -35) & (ds.latitude >= -60), drop=True)\n",
    "\n",
    "def subset_tropics(ds):\n",
    "    \"\"\"Subset dataset to the Tropics: -23.5° to 23.5° latitude.\"\"\"\n",
    "    return ds.where((ds.latitude >= -23.5) & (ds.latitude <= 23.5), drop=True)\n",
    "\n",
    "def subset_subtropics(ds):\n",
    "    \"\"\"\n",
    "    Subset dataset to the subtropics:\n",
    "    - Northern Subtropics: 23.5°N to 35°N\n",
    "    - Southern Subtropics: 23.5°S to 35°S\n",
    "    \"\"\"\n",
    "    return ds.where(\n",
    "        ((ds.latitude >= 23.5) & (ds.latitude <= 35)) | \n",
    "        ((ds.latitude <= -23.5) & (ds.latitude >= -35)),\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "def subset_africa(ds, africa_gdf):\n",
    "    \"\"\"\n",
    "    Subset an xarray dataset to the Africa region using a GeoDataFrame polygon.\n",
    "    \"\"\"\n",
    "    ds_rio = ds.rio.write_crs(\"EPSG:4326\", inplace=False)\n",
    "    return ds_rio.rio.clip(africa_gdf.geometry, africa_gdf.crs, drop=True)\n",
    "\n",
    "africa_gdf = gpd.read_file(\"Africa_outline.geojson\").to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Preprocess function for unit conversion\n",
    "def preprocess(ds):\n",
    "    if \"t2m\" in ds:\n",
    "        ds[\"t2m\"] = ds[\"t2m\"] - 273.15\n",
    "        ds[\"t2m\"].attrs[\"units\"] = \"Celsius\"\n",
    "    if \"msl\" in ds:\n",
    "        ds[\"msl\"] = ds[\"msl\"] / 100.0\n",
    "        ds[\"msl\"].attrs[\"units\"] = \"hPa\"\n",
    "    if \"tp\" in ds:\n",
    "        ds = ds.drop_vars(\"tp\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aaaeaf-1eb3-4cd6-80f5-57a48e3d0cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edbc1ba-bb20-4f82-bf2a-5b58a324437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R of IFS-HRES (apply needed subset function depending on required geographic region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a8e933-33dc-4376-902f-e71a2d5e0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory where all monthly folders are stored\n",
    "base_dir = \"../Surface Variables/\"\n",
    "\n",
    "# Define monthly date range and variables\n",
    "months = pd.date_range(\"2024-01-01\", \"2024-12-01\", freq=\"MS\")\n",
    "variables = [\"u10\", \"v10\", \"t2m\", \"msl\", \"q\"]\n",
    "\n",
    "\n",
    "# Collect monthly datasets of Pearson R per timestep\n",
    "monthly_r_datasets = []\n",
    "\n",
    "for month in months:\n",
    "    folder_str = month.strftime(\"%Y%m01\")\n",
    "    forecast_path = os.path.join(base_dir, folder_str, f\"{folder_str}_marsfc_sv_q.nc\")\n",
    "    truth_path = os.path.join(base_dir, folder_str, f\"{folder_str}_era5_fc_sv_q.nc\")\n",
    "\n",
    "    print(f\"Start for {folder_str}\")\n",
    "\n",
    "    try:\n",
    "        fc = preprocess(xr.open_dataset(forecast_path))\n",
    "        era5 = preprocess(xr.open_dataset(truth_path))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Missing data for {folder_str}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    era5 = era5.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "    # assign numbers for timesteps instead of datetime stamps\n",
    "    fc = fc.assign_coords(time=np.arange(len(fc.time)).astype(\"float64\"))\n",
    "    era5 = era5.assign_coords(time=np.arange(len(era5.time)).astype(\"float64\"))\n",
    "    print(f\"Preprocessing done for {folder_str}\")\n",
    "\n",
    "    # Subset to southern temperate\n",
    "    fc = subset_southern_temperate(fc)\n",
    "    era5 = subset_southern_temperate(era5)\n",
    "    print(f\"subset computed for {folder_str}\")\n",
    "\n",
    "    r_dict = {}\n",
    "\n",
    "    for var in variables:\n",
    "        fc_var, era5_var = xr.align(fc[var], era5[var])  # ensure same coords\n",
    "\n",
    "        # Loop over each timestep\n",
    "        r_list = []\n",
    "        for t in range(fc_var.sizes[\"time\"]):\n",
    "            fc_t = fc_var.isel(time=t).values.flatten()\n",
    "            era5_t = era5_var.isel(time=t).values.flatten()\n",
    "\n",
    "            mask = np.isfinite(fc_t) & np.isfinite(era5_t)\n",
    "            if np.any(mask):\n",
    "                r, _ = pearsonr(fc_t[mask], era5_t[mask])\n",
    "            else:\n",
    "                r = np.nan\n",
    "            r_list.append(r)\n",
    "\n",
    "        r_dict[var] = ([\"time\"], r_list)\n",
    "\n",
    "    # Create dataset for this month\n",
    "    r_ds = xr.Dataset(\n",
    "        r_dict,\n",
    "        coords={\"time\": fc[\"time\"], \"month\": [month.month]}\n",
    "    )\n",
    "\n",
    "    monthly_r_datasets.append(r_ds)\n",
    "    print(f\"Computed Pearson R per timestep for {folder_str}\")\n",
    "\n",
    "# Concatenate all months\n",
    "annual_r_ds = xr.concat(monthly_r_datasets, dim=\"month\")\n",
    "\n",
    "# Save the result\n",
    "annual_r_ds.to_netcdf(\"SouthernTemperate_marsfc_PearsonR_leadtimes.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0c790-73dc-43b3-bc15-501d128e5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation coefficient across whole year per lead time for IFS-HRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ffa9d-5902-4808-82bb-c0d8e57b3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory and variable setup\n",
    "base_dir = \"../Surface Variables/\"\n",
    "months = pd.date_range(\"2024-01-01\", \"2024-12-01\", freq=\"MS\")\n",
    "variables = [\"u10\", \"v10\", \"t2m\", \"msl\", \"q\"]\n",
    "\n",
    "\n",
    "# For storing full-year forecast and truth data\n",
    "year_fc = {var: [] for var in variables}\n",
    "year_era5 = {var: [] for var in variables}\n",
    "\n",
    "# Load and store all monthly data\n",
    "for month in months:\n",
    "    folder_str = month.strftime(\"%Y%m01\")\n",
    "    forecast_path = os.path.join(base_dir, folder_str, f\"{folder_str}_marsfc_sv_q.nc\")\n",
    "    truth_path = os.path.join(base_dir, folder_str, f\"{folder_str}_era5_fc_sv_q.nc\")\n",
    "    print(f\"Starting for {folder_str}\")\n",
    "\n",
    "    fc = preprocess(xr.open_dataset(forecast_path))\n",
    "    era5 = preprocess(xr.open_dataset(truth_path))\n",
    "    era5 = era5.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "    # Ensure numeric time for consistency\n",
    "    fc = fc.assign_coords(time=np.arange(len(fc.time)).astype(\"float64\"))\n",
    "    era5 = era5.assign_coords(time=np.arange(len(era5.time)).astype(\"float64\"))\n",
    "\n",
    "    # Subset to southern temperate\n",
    "    fc = subset_southern_temperate(fc)\n",
    "    era5 = subset_southern_temperate(era5)\n",
    "    print(f\"subset computed for {folder_str}\")\n",
    "\n",
    "    # Store monthly slices for each variable\n",
    "    for var in variables:\n",
    "        year_fc[var].append(fc[var])\n",
    "        year_era5[var].append(era5[var])\n",
    "\n",
    "    print(f\"Stored raw data for {folder_str}\")\n",
    "\n",
    "# Compute Pearson R per timestep (0–40) across all months (so, 12 * lat * lon per timestep)\n",
    "print(f\"Starting to compute annual Pearson R per timestep...\")\n",
    "\n",
    "full_year_r = {}\n",
    "\n",
    "for var in variables:\n",
    "    print(f\"Processing {var}...\")\n",
    "\n",
    "    # Concatenate monthly data along a new \"month\" dimension\n",
    "    all_fc = xr.concat(year_fc[var], dim=\"month\")\n",
    "    all_era5 = xr.concat(year_era5[var], dim=\"month\")\n",
    "\n",
    "    r_list = []\n",
    "\n",
    "    for t in range(all_fc.sizes[\"time\"]):  # Loop over 41 timesteps\n",
    "        # Extract data for timestep t across all months, then flatten spatially\n",
    "        fc_t = all_fc.isel(time=t).values.reshape(12, -1)  # (month, space)\n",
    "        era5_t = all_era5.isel(time=t).values.reshape(12, -1)\n",
    "\n",
    "        # Flatten across all months and space\n",
    "        fc_flat = fc_t.flatten()\n",
    "        era5_flat = era5_t.flatten()\n",
    "\n",
    "        mask = np.isfinite(fc_flat) & np.isfinite(era5_flat)\n",
    "        if np.any(mask):\n",
    "            r, _ = pearsonr(fc_flat[mask], era5_flat[mask])\n",
    "        else:\n",
    "            r = np.nan\n",
    "\n",
    "        r_list.append(r)\n",
    "\n",
    "    full_year_r[var] = ([\"time\"], r_list)\n",
    "\n",
    "# Final dataset with time (41 timesteps) and month = 13\n",
    "correlation_annual_ds = xr.Dataset(\n",
    "    full_year_r,\n",
    "    coords={\"time\": np.arange(41), \"month\": [13]}\n",
    ")\n",
    "\n",
    "# Save to NetCDF\n",
    "correlation_annual_ds.to_netcdf(\"SouthernTemperate_marsfc_PearsonR_leadtimes_13.nc\")\n",
    "print(\"Saved to 'SouthernTemperate_marsfc_PearsonR_leadtimes_13.nc'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc5514-fc65-4633-b7db-94597afe9fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge \"marsfc_PearsonR_leadtimes_13.nc\" with \"marsfc_PearsonR_per_timestep.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8fd09-4d33-4cf4-9869-481b0ab4dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual = xr.open_dataset(\"SouthernTemperate_marsfc_PearsonR_leadtimes_13.nc\")\n",
    "monthly = xr.open_dataset(\"SouthernTemperate_marsfc_PearsonR_leadtimes.nc\")\n",
    "\n",
    "monthly_rmse_ds_with_annual = xr.concat([monthly, annual], dim=\"month\")\n",
    "\n",
    "# Save final dataset\n",
    "monthly_rmse_ds_with_annual.to_netcdf(\"SouthernTemperate/PerLeadTime/SouthernTemperate_marsfc_PearsonR_leadtimes_w_annual.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b9630-9ebb-4a06-9d3d-e2e0090fd1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41cb7d-eccc-412c-bf99-e807dac10b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R of AIFS (apply needed subset function depending on required geographic region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c44406-8752-46c8-8e52-7654f82b43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory where all monthly folders are stored\n",
    "base_dir = \"../Surface Variables/\"\n",
    "\n",
    "# Define monthly date range and variables\n",
    "months = pd.date_range(\"2024-03-01\", \"2024-12-01\", freq=\"MS\")\n",
    "variables = [\"u10\", \"v10\", \"t2m\", \"msl\", \"q\"]\n",
    "\n",
    "# Collect monthly datasets of Pearson R per timestep\n",
    "monthly_r_datasets = []\n",
    "\n",
    "for month in months:\n",
    "    folder_str = month.strftime(\"%Y%m01\")\n",
    "    forecast_path = os.path.join(base_dir, folder_str, f\"{folder_str}_marsai_sv_q.nc\")\n",
    "    truth_path = os.path.join(base_dir, folder_str, f\"{folder_str}_era5_gcai_sv_q.nc\")\n",
    "\n",
    "    print(f\"Start for {folder_str}\")\n",
    "\n",
    "    try:\n",
    "        fc = preprocess(xr.open_dataset(forecast_path))\n",
    "        era5 = preprocess(xr.open_dataset(truth_path))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Missing data for {folder_str}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    era5 = era5.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "    # assign numbers for timesteps instead of datetime stamps\n",
    "    fc = fc.assign_coords(time=np.arange(len(fc.time)).astype(\"float64\"))\n",
    "    era5 = era5.assign_coords(time=np.arange(len(era5.time)).astype(\"float64\"))\n",
    "\n",
    "    print(f\"Preprocessing done for {folder_str}\")\n",
    "\n",
    "    # Subset to southern temperate\n",
    "    fc = subset_southern_temperate(fc)\n",
    "    era5 = subset_southern_temperate(era5)\n",
    "    print(f\"subset computed for {folder_str}\")\n",
    "\n",
    "    r_dict = {}\n",
    "\n",
    "    for var in variables:\n",
    "        fc_var, era5_var = xr.align(fc[var], era5[var])  # ensure same coords\n",
    "\n",
    "        # Loop over each timestep\n",
    "        r_list = []\n",
    "        for t in range(fc_var.sizes[\"time\"]):\n",
    "            fc_t = fc_var.isel(time=t).values.flatten()\n",
    "            era5_t = era5_var.isel(time=t).values.flatten()\n",
    "\n",
    "            mask = np.isfinite(fc_t) & np.isfinite(era5_t)\n",
    "            if np.any(mask):\n",
    "                r, _ = pearsonr(fc_t[mask], era5_t[mask])\n",
    "            else:\n",
    "                r = np.nan\n",
    "            r_list.append(r)\n",
    "\n",
    "        r_dict[var] = ([\"time\"], r_list)\n",
    "\n",
    "    # Create dataset for this month\n",
    "    r_ds = xr.Dataset(\n",
    "        r_dict,\n",
    "        coords={\"time\": fc[\"time\"], \"month\": [month.month]}\n",
    "    )\n",
    "\n",
    "    monthly_r_datasets.append(r_ds)\n",
    "    print(f\"Computed Pearson R per timestep for {folder_str}\")\n",
    "\n",
    "# Concatenate all months\n",
    "annual_r_ds = xr.concat(monthly_r_datasets, dim=\"month\")\n",
    "\n",
    "# Save the result\n",
    "annual_r_ds.to_netcdf(\"SouthernTemperate_marsai_PearsonR_leadtimes.nc\")\n",
    "print(\"Saved to 'SouthernTemperate_marsai_PearsonR_leadtimes.nc'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ecc1c2-0ff8-4cbb-8c03-ef967eac56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation coefficient across whole year per lead time for AIFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99fe425-26c9-4e25-a636-7a1b0ab73b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory and variable setup\n",
    "base_dir = \"../Surface Variables/\"\n",
    "months = pd.date_range(\"2024-03-01\", \"2024-12-01\", freq=\"MS\")\n",
    "variables = [\"u10\", \"v10\", \"t2m\", \"msl\", \"q\"]\n",
    "\n",
    "\n",
    "# For storing full-year forecast and truth data\n",
    "year_fc = {var: [] for var in variables}\n",
    "year_era5 = {var: [] for var in variables}\n",
    "\n",
    "# Load and store all monthly data\n",
    "for month in months:\n",
    "    folder_str = month.strftime(\"%Y%m01\")\n",
    "    forecast_path = os.path.join(base_dir, folder_str, f\"{folder_str}_marsai_sv_q.nc\")\n",
    "    truth_path = os.path.join(base_dir, folder_str, f\"{folder_str}_era5_gcai_sv_q.nc\")\n",
    "    print(f\"Starting for {folder_str}\")\n",
    "\n",
    "    fc = preprocess(xr.open_dataset(forecast_path))\n",
    "    era5 = preprocess(xr.open_dataset(truth_path))\n",
    "    era5 = era5.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "    # Ensure numeric time for consistency\n",
    "    fc = fc.assign_coords(time=np.arange(len(fc.time)).astype(\"float64\"))\n",
    "    era5 = era5.assign_coords(time=np.arange(len(era5.time)).astype(\"float64\"))\n",
    "    print(f\"preprocessing done for {folder_str}\")\n",
    "\n",
    "    # Subset to southern temperate\n",
    "    fc = subset_southern_temperate(fc)\n",
    "    era5 = subset_southern_temperate(era5)\n",
    "    print(f\"subset computed for {folder_str}\")\n",
    "\n",
    "    # Store monthly slices for each variable\n",
    "    for var in variables:\n",
    "        year_fc[var].append(fc[var])\n",
    "        year_era5[var].append(era5[var])\n",
    "\n",
    "    print(f\"Stored raw data for {folder_str}\")\n",
    "\n",
    "# Compute Pearson R per timestep (0–40) across all months (so, 12 * lat * lon per timestep)\n",
    "print(f\"Starting to compute annual Pearson R per timestep...\")\n",
    "\n",
    "full_year_r = {}\n",
    "\n",
    "for var in variables:\n",
    "    print(f\"Processing {var}...\")\n",
    "\n",
    "    # Concatenate monthly data along a new \"month\" dimension\n",
    "    all_fc = xr.concat(year_fc[var], dim=\"month\")\n",
    "    all_era5 = xr.concat(year_era5[var], dim=\"month\")\n",
    "\n",
    "    r_list = []\n",
    "\n",
    "    for t in range(all_fc.sizes[\"time\"]):  # Loop over 41 timesteps\n",
    "        # Extract data for timestep t across all months, then flatten spatially\n",
    "        fc_t = all_fc.isel(time=t).values.reshape(10, -1)  # (month, space)\n",
    "        era5_t = all_era5.isel(time=t).values.reshape(10, -1)\n",
    "\n",
    "        # Flatten across all months and space\n",
    "        fc_flat = fc_t.flatten()\n",
    "        era5_flat = era5_t.flatten()\n",
    "\n",
    "        mask = np.isfinite(fc_flat) & np.isfinite(era5_flat)\n",
    "        if np.any(mask):\n",
    "            r, _ = pearsonr(fc_flat[mask], era5_flat[mask])\n",
    "        else:\n",
    "            r = np.nan\n",
    "\n",
    "        r_list.append(r)\n",
    "\n",
    "    full_year_r[var] = ([\"time\"], r_list)\n",
    "\n",
    "# Final dataset with time (41 timesteps) and month = 13\n",
    "correlation_annual_ds = xr.Dataset(\n",
    "    full_year_r,\n",
    "    coords={\"time\": np.arange(41), \"month\": [13]}\n",
    ")\n",
    "\n",
    "# Save to NetCDF\n",
    "correlation_annual_ds.to_netcdf(\"SouthernTemperate_marsai_PearsonR_leadtimes_13.nc\")\n",
    "print(\"Saved to 'SouthernTemperate_marsai_PearsonR_leadtimes_13.nc'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfdebaf-9db6-4f92-acd1-85e7077ec242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge \"marsai_PearsonR_leadtimes.nc\" with \"marsai_PearsonR_leadtimes_13.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482ff1d-655a-4e2c-91d7-767ca90ca444",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual = xr.open_dataset(\"SouthernTemperate_marsai_PearsonR_leadtimes_13.nc\")\n",
    "monthly = xr.open_dataset(\"SouthernTemperate_marsai_PearsonR_leadtimes.nc\")\n",
    "\n",
    "monthly_rmse_ds_with_annual = xr.concat([monthly, annual], dim=\"month\")\n",
    "\n",
    "# Save final dataset\n",
    "monthly_rmse_ds_with_annual.to_netcdf(\"SouthernTemperate/PerLeadTime/SouthernTemperate_marsai_PearsonR_leadtimes_w_annual.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0d172-cc13-4682-af84-48bcad11e77d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dcb257-48fe-44ba-b53b-c18e05acfc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R of GraphCast (apply needed subset function depending on required geographic region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d2d0c7-0a86-485b-aa87-8889a733f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory where all monthly folders are stored\n",
    "base_dir = \"../Surface Variables/\"\n",
    "\n",
    "# Define monthly date range and variables\n",
    "months = pd.date_range(\"2024-01-01\", \"2024-12-01\", freq=\"MS\")\n",
    "variables = [\"u10\", \"v10\", \"t2m\", \"msl\", \"q\"]\n",
    "\n",
    "\n",
    "# Collect monthly datasets of Pearson R per timestep\n",
    "monthly_r_datasets = []\n",
    "\n",
    "for month in months:\n",
    "    folder_str = month.strftime(\"%Y%m01\")\n",
    "    forecast_path = os.path.join(base_dir, folder_str, f\"{folder_str}_gc_sv_q.nc\")\n",
    "    truth_path = os.path.join(base_dir, folder_str, f\"{folder_str}_era5_gcai_sv_q.nc\")\n",
    "\n",
    "    print(f\"Start for {folder_str}\")\n",
    "\n",
    "    try:\n",
    "        fc = preprocess(xr.open_dataset(forecast_path))\n",
    "        era5 = preprocess(xr.open_dataset(truth_path))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Missing data for {folder_str}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    era5 = era5.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "    # Drop the existing \"time\" coordinate to avoid conflicts\n",
    "    if \"time\" in fc.coords:\n",
    "        fc = fc.drop_vars(\"time\")\n",
    "\n",
    "    # Swap the \"step\" dimension with \"valid_time\" and rename it to \"time\"\n",
    "    fc = fc.swap_dims({\"step\": \"valid_time\"})  # make valid_time a dimension\n",
    "    fc = fc.rename({\"valid_time\": \"time\"})     # rename the dimension to \"time\"\n",
    "\n",
    "    # assign numbers for timesteps instead of datetime stamps\n",
    "    fc = fc.assign_coords(time=np.arange(len(fc.time)).astype(\"float64\"))\n",
    "    era5 = era5.assign_coords(time=np.arange(len(era5.time)).astype(\"float64\"))\n",
    "\n",
    "    print(f\"Preprocessing done for {folder_str}\")\n",
    "\n",
    "    # Subset to southern temperate\n",
    "    fc = subset_southern_temperate(fc)\n",
    "    era5 = subset_southern_temperate(era5)\n",
    "    print(f\"subset computed for {folder_str}\")\n",
    "\n",
    "    r_dict = {}\n",
    "\n",
    "    for var in variables:\n",
    "        fc_var, era5_var = xr.align(fc[var], era5[var])  # ensure same coords\n",
    "\n",
    "        # Loop over each timestep\n",
    "        r_list = []\n",
    "        for t in range(fc_var.sizes[\"time\"]):\n",
    "            fc_t = fc_var.isel(time=t).values.flatten()\n",
    "            era5_t = era5_var.isel(time=t).values.flatten()\n",
    "\n",
    "            mask = np.isfinite(fc_t) & np.isfinite(era5_t)\n",
    "            if np.any(mask):\n",
    "                r, _ = pearsonr(fc_t[mask], era5_t[mask])\n",
    "            else:\n",
    "                r = np.nan\n",
    "            r_list.append(r)\n",
    "\n",
    "        r_dict[var] = ([\"time\"], r_list)\n",
    "\n",
    "    # Create dataset for this month\n",
    "    r_ds = xr.Dataset(\n",
    "        r_dict,\n",
    "        coords={\"time\": fc[\"time\"], \"month\": [month.month]}\n",
    "    )\n",
    "\n",
    "    monthly_r_datasets.append(r_ds)\n",
    "    print(f\"Computed Pearson R per timestep for {folder_str}\")\n",
    "\n",
    "# Concatenate all months\n",
    "annual_r_ds = xr.concat(monthly_r_datasets, dim=\"month\")\n",
    "\n",
    "# Save the result\n",
    "annual_r_ds.to_netcdf(\"SouthernTemperate_gc_PearsonR_leadtimes.nc\")\n",
    "print(\"Saved to 'SouthernTemperate_gc_PearsonR_leadtimes.nc'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb83139-ea9a-4b03-85ca-7002ec937d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute R across whole year per lead time for graphcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c3b23-ea60-4032-bdaf-f2131febecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory and variable setup\n",
    "base_dir = \"../Surface Variables/\"\n",
    "months = pd.date_range(\"2024-01-01\", \"2024-12-01\", freq=\"MS\")\n",
    "variables = [\"u10\", \"v10\", \"t2m\", \"msl\", \"q\"]\n",
    "\n",
    "# For storing full-year forecast and truth data\n",
    "year_fc = {var: [] for var in variables}\n",
    "year_era5 = {var: [] for var in variables}\n",
    "\n",
    "# Load and store all monthly data\n",
    "for month in months:\n",
    "    folder_str = month.strftime(\"%Y%m01\")\n",
    "    forecast_path = os.path.join(base_dir, folder_str, f\"{folder_str}_gc_sv_q.nc\")\n",
    "    truth_path = os.path.join(base_dir, folder_str, f\"{folder_str}_era5_gcai_sv_q.nc\")\n",
    "    print(f\"Starting for {folder_str}\")\n",
    "\n",
    "    fc = preprocess(xr.open_dataset(forecast_path))\n",
    "    era5 = preprocess(xr.open_dataset(truth_path))\n",
    "    era5 = era5.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "    # Drop the existing \"time\" coordinate to avoid conflicts\n",
    "    if \"time\" in fc.coords:\n",
    "        fc = fc.drop_vars(\"time\")\n",
    "\n",
    "    # Swap the \"step\" dimension with \"valid_time\" and rename it to \"time\"\n",
    "    fc = fc.swap_dims({\"step\": \"valid_time\"})  # make valid_time a dimension\n",
    "    fc = fc.rename({\"valid_time\": \"time\"})     # rename the dimension to \"time\"\n",
    "\n",
    "    # Ensure numeric time for consistency\n",
    "    fc = fc.assign_coords(time=np.arange(len(fc.time)).astype(\"float64\"))\n",
    "    era5 = era5.assign_coords(time=np.arange(len(era5.time)).astype(\"float64\"))\n",
    "    print(f\"preprocessed for {folder_str}\")\n",
    "\n",
    "    # Subset to southern temperate\n",
    "    fc = subset_southern_temperate(fc)\n",
    "    era5 = subset_southern_temperate(era5)\n",
    "    print(f\"subset computed for {folder_str}\")\n",
    "\n",
    "    # Store monthly slices for each variable\n",
    "    for var in variables:\n",
    "        year_fc[var].append(fc[var])\n",
    "        year_era5[var].append(era5[var])\n",
    "\n",
    "    print(f\"Stored raw data for {folder_str}\")\n",
    "\n",
    "# Compute Pearson R per timestep (0–40) across all months (so, 12 * lat * lon per timestep)\n",
    "print(f\"Starting to compute annual Pearson R per timestep...\")\n",
    "\n",
    "full_year_r = {}\n",
    "\n",
    "for var in variables:\n",
    "    print(f\"Processing {var}...\")\n",
    "\n",
    "    # Concatenate monthly data along a new \"month\" dimension\n",
    "    all_fc = xr.concat(year_fc[var], dim=\"month\")\n",
    "    all_era5 = xr.concat(year_era5[var], dim=\"month\")\n",
    "\n",
    "    r_list = []\n",
    "\n",
    "    for t in range(all_fc.sizes[\"time\"]):  # Loop over 41 timesteps\n",
    "        # Extract data for timestep t across all months, then flatten spatially\n",
    "        fc_t = all_fc.isel(time=t).values.reshape(12, -1)  # (month, space)\n",
    "        era5_t = all_era5.isel(time=t).values.reshape(12, -1)\n",
    "\n",
    "        # Flatten across all months and space\n",
    "        fc_flat = fc_t.flatten()\n",
    "        era5_flat = era5_t.flatten()\n",
    "\n",
    "        mask = np.isfinite(fc_flat) & np.isfinite(era5_flat)\n",
    "        if np.any(mask):\n",
    "            r, _ = pearsonr(fc_flat[mask], era5_flat[mask])\n",
    "        else:\n",
    "            r = np.nan\n",
    "\n",
    "        r_list.append(r)\n",
    "\n",
    "    full_year_r[var] = ([\"time\"], r_list)\n",
    "\n",
    "# Final dataset with time (41 timesteps) and month = 13\n",
    "correlation_annual_ds = xr.Dataset(\n",
    "    full_year_r,\n",
    "    coords={\"time\": np.arange(41), \"month\": [13]}\n",
    ")\n",
    "\n",
    "# Save to NetCDF\n",
    "correlation_annual_ds.to_netcdf(\"SouthernTemperate_gc_PearsonR_leadtimes_13.nc\")\n",
    "print(\"Saved to 'SouthernTemperate_gc_PearsonR_leadtimes_13.nc'\")\n",
    "print(correlation_annual_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e658a8-74b6-4bc6-b960-7e147cbd7baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge \"gc_PearsonR_leadtimes.nc\" with \"gc_PearsonR_leadtimes_13.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d91f2-9b0c-45ae-81db-23379c612ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual = xr.open_dataset(\"SouthernTemperate_gc_PearsonR_leadtimes_13.nc\")\n",
    "monthly = xr.open_dataset(\"SouthernTemperate_gc_PearsonR_leadtimes.nc\")\n",
    "\n",
    "monthly_rmse_ds_with_annual = xr.concat([monthly, annual], dim=\"month\")\n",
    "\n",
    "# Save final dataset\n",
    "monthly_rmse_ds_with_annual.to_netcdf(\"SouthernTemperate/PerLeadTime/SouthernTemperate_gc_PearsonR_leadtimes_w_annual.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ec058-edbd-4b7c-8724-6838a25630d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a562255-c49a-44c7-b34c-23f4f450354d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5dba8-4791-439f-a252-a69ff1b2097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all models into 1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce31f009-ee23-496f-b49a-6cdffd9f117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "air = xr.open_dataset(\"SouthernTemperate/PerLeadTime/SouthernTemperate_marsai_PearsonR_leadtimes_w_annual.nc\")\n",
    "gcr = xr.open_dataset(\"SouthernTemperate/PerLeadTime/SouthernTemperate_gc_PearsonR_leadtimes_w_annual.nc\")\n",
    "fcr = xr.open_dataset(\"SouthernTemperate/PerLeadTime/SouthernTemperate_marsfc_PearsonR_leadtimes_w_annual.nc\")\n",
    "\n",
    "# Ensure all datasets have the full month range 1 to 13\n",
    "full_months = np.arange(1, 14)\n",
    "\n",
    "# Reindex to include all months, filling missing with NaN\n",
    "air = air.reindex(month=full_months)\n",
    "gcr = gcr.reindex(month=full_months)\n",
    "fcr = fcr.reindex(month=full_months)\n",
    "\n",
    "# Drop any unrelated extra coordinates to match structure \n",
    "drop_coords = [\"meanSea\", \"surface\", \"isobaricInhPa\", \"number\", \"expver\", \"step\"]\n",
    "gcr = gcr.drop_vars([c for c in drop_coords if c in gcr])\n",
    "air = air.drop_vars([c for c in drop_coords if c in air])\n",
    "fcr = fcr.drop_vars([c for c in drop_coords if c in fcr])\n",
    "\n",
    "# Stack them into a new 'model' dimension\n",
    "combined = xr.concat([air, gcr, fcr], dim=\"model\")\n",
    "\n",
    "# Add model labels\n",
    "combined = combined.assign_coords(model=[\"marsai\", \"gc\", \"marsfc\"])\n",
    "\n",
    "# Save the merged dataset (optional)\n",
    "combined.to_netcdf(\"SouthernTemperate/PerLeadTime/SouthernTemperate_PearsonR_leadtimes_allmodels.nc\")\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Merged dataset created with shape:\", combined.sizes)\n",
    "print(\"Models:\", combined.model.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
