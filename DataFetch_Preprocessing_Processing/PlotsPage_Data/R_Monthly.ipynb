{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a69d355-40d6-4ab3-add5-f0f90095b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy.stats import pearsonr\n",
    "import geopandas as gpd\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86171496-ce57-4cf1-8643-e781b1e9c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R of the forecast averaged over all time steps, latitudes, and longitudes per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d429b1a-dba2-452b-afdd-732fecc29421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_northern_temperate(ds):\n",
    "    \"\"\"Subset dataset to the Northern Temperate Zone: 35°N to 60°N.\"\"\"\n",
    "    return ds.where((ds.latitude >= 35) & (ds.latitude <= 60), drop=True)\n",
    "\n",
    "def subset_southern_temperate(ds):\n",
    "    \"\"\"Subset dataset to the Northern Temperate Zone: 35°N to 60°N.\"\"\"\n",
    "    return ds.where((ds.latitude <= -35) & (ds.latitude >= -60), drop=True)\n",
    "\n",
    "# Function to subset to subpolar and polar regions\n",
    "def subset_polar_regions(ds):\n",
    "    \"\"\"Subset dataset to the (Sub-)Polar Zones: 60°N to 90°N and -60°N to -90°N \"\"\"\n",
    "    return ds.where((ds.latitude >= 60) | (ds.latitude <= -60), drop=True)\n",
    "\n",
    "def subset_tropics(ds):\n",
    "    \"\"\"Subset dataset to the Tropics: -23.5° to 23.5° latitude.\"\"\"\n",
    "    return ds.where((ds.latitude >= -23.5) & (ds.latitude <= 23.5), drop=True)\n",
    "\n",
    "def subset_subtropics(ds):\n",
    "    \"\"\"\n",
    "    Subset dataset to the subtropics:\n",
    "    - Northern Subtropics: 23.5°N to 35°N\n",
    "    - Southern Subtropics: 23.5°S to 35°S\n",
    "    \"\"\"\n",
    "    return ds.where(\n",
    "        ((ds.latitude >= 23.5) & (ds.latitude <= 35)) | \n",
    "        ((ds.latitude <= -23.5) & (ds.latitude >= -35)),\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "def subset_africa(ds, africa_gdf):\n",
    "    \"\"\"\n",
    "    Subset an xarray dataset to the Africa region using a GeoDataFrame polygon.\n",
    "    \"\"\"\n",
    "    ds_rio = ds.rio.write_crs(\"EPSG:4326\", inplace=False)\n",
    "    return ds_rio.rio.clip(africa_gdf.geometry, africa_gdf.crs, drop=True)\n",
    "\n",
    "africa_gdf = gpd.read_file(\"Africa_outline.geojson\").to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Preprocess function for unit conversion\n",
    "def preprocess(ds):\n",
    "    if \"t2m\" in ds:\n",
    "        ds[\"t2m\"] = ds[\"t2m\"] - 273.15\n",
    "        ds[\"t2m\"].attrs[\"units\"] = \"Celsius\"\n",
    "    if \"msl\" in ds:\n",
    "        ds[\"msl\"] = ds[\"msl\"] / 100.0\n",
    "        ds[\"msl\"].attrs[\"units\"] = \"hPa\"\n",
    "    if \"tp\" in ds:\n",
    "        ds = ds.drop_vars(\"tp\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e491432d-5c53-42d2-8a87-a7bc7dfbe148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba41ce-d205-40cb-836c-5913803a0191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R of IFS-HRES (apply needed subset function depending on required geographic region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7057218-b8e2-42ae-82d7-634e298db5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory where all monthly folders are stored\n",
    "base_dir = \"../Surface Variables/\"\n",
    "\n",
    "# Define monthly date range and variables\n",
    "months = pd.date_range(\"2024-01-01\", \"2024-12-01\", freq=\"MS\")\n",
    "variables = [\"u10\", \"v10\", \"t2m\", \"msl\", \"q\"]\n",
    "\n",
    "\n",
    "# Collect monthly correlation datasets\n",
    "monthly_r_datasets = []\n",
    "\n",
    "for month in months:\n",
    "    folder_str = month.strftime(\"%Y%m01\")\n",
    "    forecast_path = os.path.join(base_dir, folder_str, f\"{folder_str}_marsfc_sv_q.nc\")\n",
    "    truth_path = os.path.join(base_dir, folder_str, f\"{folder_str}_era5_fc_sv_q.nc\")\n",
    "\n",
    "    print(f\" Start for {folder_str}\")\n",
    "\n",
    "    try:\n",
    "        fc = preprocess(xr.open_dataset(forecast_path))\n",
    "        era5 = preprocess(xr.open_dataset(truth_path))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Missing data for {folder_str}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\" Preprocessing done for {folder_str}\")\n",
    "    \n",
    "    era5 = era5.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "    # Subset to polar regions\n",
    "    # fc = subset_polar_regions(fc)\n",
    "    # era5 = subset_polar_regions(era5)\n",
    "\n",
    "    # Subset to southern temperate\n",
    "    fc = subset_southern_temperate(fc)\n",
    "    era5 = subset_southern_temperate(era5)\n",
    "    print(f\"subset computed for {folder_str}\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for var in variables:\n",
    "        fc_var, era5_var = xr.align(fc[var], era5[var])\n",
    "        fc_flat = fc_var.values.flatten()\n",
    "        era5_flat = era5_var.values.flatten()\n",
    "        valid_mask = np.isfinite(fc_flat) & np.isfinite(era5_flat)\n",
    "\n",
    "        if np.any(valid_mask):\n",
    "            r, _ = pearsonr(fc_flat[valid_mask], era5_flat[valid_mask])\n",
    "        else:\n",
    "            r = np.nan\n",
    "\n",
    "        results.append((var, r))\n",
    "\n",
    "    # Create dataset for this month\n",
    "    month_ds = xr.Dataset(\n",
    "        {var: ([\"month\"], [r]) for var, r in results},\n",
    "        coords={\"month\": [month.month]} # sets coordinate value to 1, 2, ..., 12\n",
    "    )\n",
    "\n",
    "    monthly_r_datasets.append(month_ds)\n",
    "    print(f\" Computed Pearson R for {folder_str}\")\n",
    "\n",
    "# Concatenate all months\n",
    "annual_r_ds = xr.concat(monthly_r_datasets, dim=\"month\")\n",
    "\n",
    "# Compute average across months\n",
    "r_mean = annual_r_ds.mean(dim=\"month\", skipna=True)\n",
    "r_mean = r_mean.expand_dims(month=[13])  # 13th month is average\n",
    "\n",
    "# Append mean to dataset\n",
    "annual_r_ds_with_mean = xr.concat([annual_r_ds, r_mean], dim=\"month\")\n",
    "\n",
    "# Save the final dataset\n",
    "annual_r_ds_with_mean.to_netcdf(\"SouthernTemperate/PerMonth/SouthernTemperate_marsfc_PearsonR_monthly.nc\")\n",
    "print(\"Pearson R (with 13th-month average) saved to 'SouthernTemperate/PerMonth/SouthernTemperate_marsfc_PearsonR_monthly.nc'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa7f13-68e3-471e-9988-7356c02fda22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17807b43-283b-45cd-a9d8-bb8550f34d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R of AIFS (apply needed subset function depending on required geographic region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b24ea-279e-4aa1-b75a-8a8b8ff7cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory where all monthly folders are stored\n",
    "base_dir = \"../Surface Variables/\"\n",
    "\n",
    "# Define monthly date range and variables\n",
    "months = pd.date_range(\"2024-03-01\", \"2024-12-01\", freq=\"MS\")\n",
    "variables = [\"u10\", \"v10\", \"t2m\", \"msl\", \"q\"]\n",
    "\n",
    "\n",
    "# Collect monthly correlation datasets\n",
    "monthly_r_datasets = []\n",
    "\n",
    "for month in months:\n",
    "    folder_str = month.strftime(\"%Y%m01\")\n",
    "    forecast_path = os.path.join(base_dir, folder_str, f\"{folder_str}_marsai_sv_q.nc\")\n",
    "    truth_path = os.path.join(base_dir, folder_str, f\"{folder_str}_era5_gcai_sv_q.nc\")\n",
    "\n",
    "    print(f\" Start for {folder_str}\")\n",
    "\n",
    "    try:\n",
    "        ai = preprocess(xr.open_dataset(forecast_path))\n",
    "        era5 = preprocess(xr.open_dataset(truth_path))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Missing data for {folder_str}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\" Preprocessing done for {folder_str}\")\n",
    "    \n",
    "    era5 = era5.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "    # Subset to southern temperate\n",
    "    ai = subset_southern_temperate(ai)\n",
    "    era5 = subset_southern_temperate(era5)\n",
    "    print(f\"subset computed for {folder_str}\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for var in variables:\n",
    "        ai_var, era5_var = xr.align(ai[var], era5[var])\n",
    "        ai_flat = ai_var.values.flatten()\n",
    "        era5_flat = era5_var.values.flatten()\n",
    "        valid_mask = np.isfinite(ai_flat) & np.isfinite(era5_flat)\n",
    "\n",
    "        if np.any(valid_mask):\n",
    "            r, _ = pearsonr(ai_flat[valid_mask], era5_flat[valid_mask])\n",
    "        else:\n",
    "            r = np.nan\n",
    "\n",
    "        results.append((var, r))\n",
    "\n",
    "    # Create dataset for this month\n",
    "    month_ds = xr.Dataset(\n",
    "        {var: ([\"month\"], [r]) for var, r in results},\n",
    "        coords={\"month\": [month.month]} # sets coordinate value to 1, 2, ..., 12\n",
    "    )\n",
    "\n",
    "    monthly_r_datasets.append(month_ds)\n",
    "    print(f\" Computed Pearson R for {folder_str}\")\n",
    "\n",
    "# Concatenate all months\n",
    "annual_r_ds = xr.concat(monthly_r_datasets, dim=\"month\")\n",
    "\n",
    "# Compute average across months\n",
    "r_mean = annual_r_ds.mean(dim=\"month\", skipna=True)\n",
    "r_mean = r_mean.expand_dims(month=[13])  # 13th month is average\n",
    "\n",
    "# Append mean to dataset\n",
    "annual_r_ds_with_mean = xr.concat([annual_r_ds, r_mean], dim=\"month\")\n",
    "\n",
    "# Save the final dataset\n",
    "annual_r_ds_with_mean.to_netcdf(\"SouthernTemperate/PerMonth/SouthernTemperate_marsai_PearsonR_monthly.nc\")\n",
    "print(\"Pearson R (with 13th-month average) saved to 'SouthernTemperate/PerMonth/SouthernTemperate_marsai_PearsonR_monthly.nc'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4bca55-de84-4924-9cf2-b448331f8a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30bff03-b019-405c-aa64-be72d955a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R of GraphCast (apply needed subset function depending on required geographic region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0914b9-d0e2-4d95-b8dd-ec0557cab0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory where all monthly folders are stored\n",
    "base_dir = \"../Surface Variables/\"\n",
    "\n",
    "# Define monthly date range and variables\n",
    "months = pd.date_range(\"2024-01-01\", \"2024-12-01\", freq=\"MS\")\n",
    "variables = [\"u10\", \"v10\", \"t2m\", \"msl\", \"q\"]\n",
    "\n",
    "\n",
    "# Collect monthly correlation datasets\n",
    "monthly_r_datasets = []\n",
    "\n",
    "for month in months:\n",
    "    folder_str = month.strftime(\"%Y%m01\")\n",
    "    forecast_path = os.path.join(base_dir, folder_str, f\"{folder_str}_gc_sv_q.nc\")\n",
    "    truth_path = os.path.join(base_dir, folder_str, f\"{folder_str}_era5_gcai_sv_q.nc\")\n",
    "\n",
    "    print(f\" Start for {folder_str}\")\n",
    "\n",
    "    try:\n",
    "        gc = preprocess(xr.open_dataset(forecast_path))\n",
    "        era5 = preprocess(xr.open_dataset(truth_path))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Missing data for {folder_str}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    era5 = era5.rename({\"valid_time\": \"time\"})\n",
    "    # Drop the existing \"time\" coordinate to avoid conflicts\n",
    "    if \"time\" in gc.coords:\n",
    "        gc = gc.drop_vars(\"time\")\n",
    "\n",
    "    # Swap the \"step\" dimension with \"valid_time\" and rename it to \"time\"\n",
    "    gc = gc.swap_dims({\"step\": \"valid_time\"})  # make valid_time a dimension\n",
    "    gc = gc.rename({\"valid_time\": \"time\"})     # rename the dimension to \"time\"\n",
    "    \n",
    "    print(f\" Preprocessing done for {folder_str}\")\n",
    "\n",
    "    # Subset to southern temperate\n",
    "    gc = subset_southern_temperate(gc)\n",
    "    era5 = subset_southern_temperate(era5)\n",
    "    print(f\"subset computed for {folder_str}\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for var in variables:\n",
    "        gc_var, era5_var = xr.align(gc[var], era5[var])\n",
    "        gc_flat = gc_var.values.flatten()\n",
    "        era5_flat = era5_var.values.flatten()\n",
    "        valid_mask = np.isfinite(gc_flat) & np.isfinite(era5_flat)\n",
    "\n",
    "        if np.any(valid_mask):\n",
    "            r, _ = pearsonr(gc_flat[valid_mask], era5_flat[valid_mask])\n",
    "        else:\n",
    "            r = np.nan\n",
    "\n",
    "        results.append((var, r))\n",
    "\n",
    "    # Create dataset for this month\n",
    "    month_ds = xr.Dataset(\n",
    "        {var: ([\"month\"], [r]) for var, r in results},\n",
    "        coords={\"month\": [month.month]} # sets coordinate value to 1, 2, ..., 12\n",
    "    )\n",
    "\n",
    "    monthly_r_datasets.append(month_ds)\n",
    "    print(f\" Computed Pearson R for {folder_str}\")\n",
    "\n",
    "# Concatenate all months\n",
    "annual_r_ds = xr.concat(monthly_r_datasets, dim=\"month\")\n",
    "\n",
    "# Compute average across months\n",
    "r_mean = annual_r_ds.mean(dim=\"month\", skipna=True)\n",
    "r_mean = r_mean.expand_dims(month=[13])  # 13th month is average\n",
    "\n",
    "# Append mean to dataset\n",
    "annual_r_ds_with_mean = xr.concat([annual_r_ds, r_mean], dim=\"month\")\n",
    "\n",
    "# Save the final dataset\n",
    "annual_r_ds_with_mean.to_netcdf(\"SouthernTemperate/PerMonth/SouthernTemperate_gc_PearsonR_monthly.nc\")\n",
    "print(\"Pearson R (with 13th-month average) saved to 'SouthernTemperate/PerMonth/SouthernTemperate_gc_PearsonR_monthly.nc'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f374f966-5392-4556-8845-4bb3565a3ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43fdf9-9ff8-44a4-a6fc-ca4931058e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all models into 1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52eddd-b39a-4dd1-9246-8911842662bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "gcr = xr.open_dataset(\"SouthernTemperate/PerMonth/SouthernTemperate_gc_PearsonR_monthly.nc\")\n",
    "fcr = xr.open_dataset(\"SouthernTemperate/PerMonth/SouthernTemperate_marsfc_PearsonR_monthly.nc\")\n",
    "air = xr.open_dataset(\"SouthernTemperate/PerMonth/SouthernTemperate_marsai_PearsonR_monthly.nc\")\n",
    "\n",
    "# Ensure all datasets have the full month range 1 to 13\n",
    "full_months = np.arange(1, 14)\n",
    "\n",
    "# Reindex to include all months, filling missing with NaN\n",
    "air = air.reindex(month=full_months)\n",
    "gcr = gcr.reindex(month=full_months)\n",
    "fcr = fcr.reindex(month=full_months)\n",
    "\n",
    "# Drop any unrelated extra coordinates to match structure \n",
    "drop_coords = [\"meanSea\", \"surface\", \"isobaricInhPa\", \"number\"]\n",
    "gcr = gcr.drop_vars([c for c in drop_coords if c in gcr])\n",
    "\n",
    "# Stack them into a new 'model' dimension\n",
    "combined = xr.concat([air, gcr, fcr], dim=\"model\")\n",
    "\n",
    "# Add model labels\n",
    "combined = combined.assign_coords(model=[\"marsai\", \"gc\", \"marsfc\"])\n",
    "\n",
    "# Save the merged dataset (optional)\n",
    "combined.to_netcdf(\"SouthernTemperate/PerMonth/SouthernTemperate_PearsonR_monthly_allmodels.nc\")\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Merged dataset created with shape:\", combined.sizes)\n",
    "print(\"Models:\", combined.model.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
