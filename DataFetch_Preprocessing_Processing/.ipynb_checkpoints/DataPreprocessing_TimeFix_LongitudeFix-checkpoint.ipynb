{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d15fa3-449e-4961-8bf1-902500062a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import tempfile\n",
    "import rasterio\n",
    "import rioxarray as rio\n",
    "from netCDF4 import Dataset\n",
    "import cdsapi\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad4919-8662-4027-addd-2c6ab627396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to slice the ERA5 files to match the IFS-HRES files and the AIFS and GraphCast files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1dd68b-17e5-4f95-b377-c43b3960e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_era5_time_range(input_file_path, output_file_path, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Filters an ERA5 NetCDF dataset (time steps are saved as \"valid_time\") \n",
    "    based on a specified time range and saves it to a new file.\n",
    "\n",
    "    Parameters:\n",
    "        input_file_path (str): Path to the original NetCDF file.\n",
    "        output_file_path (str): Path where the filtered NetCDF file will be saved.\n",
    "        start_time (str): Start time for filtering (ISO 8601 format, e.g., \"2023-12-01T06:00:00\").\n",
    "        end_time (str): End time for filtering (ISO 8601 format, e.g., \"2023-12-11T06:00:00\").\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    era5ds = xr.open_dataset(input_file_path)\n",
    "\n",
    "    try:\n",
    "        # Filter the dataset for the specified time range\n",
    "        filtered_era5ds = era5ds.sel(valid_time=slice(start_time, end_time))\n",
    "\n",
    "        # Save the filtered dataset to the specified output path\n",
    "        filtered_era5ds.to_netcdf(output_file_path)\n",
    "\n",
    "        print(f\"Filtered data saved to {output_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        era5ds.close()\n",
    "        if 'filtered_era5ds' in locals():\n",
    "            filtered_era5ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7107ad-6aba-4dd3-b9ff-18d3691aedf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice all ERA5 files time range to match IFS-HRES time range\n",
    "# Time range: 2024-XX-01T00:00:00 - 2024-XX-11T00:00:00\n",
    "# Apply the function to all monthly ERA5 files both in the Pressure Variable folder and the Surface Variable folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221a6e6f-06fa-468c-b3e9-bba0b47e2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"Pressure Variables/20240301/20240301_era5_q.nc\"\n",
    "output_file_path = \"Pressure Variables/20240301/20240301_era5_fc_q.nc\"\n",
    "start_time = \"2024-03-01T00:00:00\"\n",
    "end_time = \"2024-03-11T00:00:00\"\n",
    "filter_era5_time_range(input_file_path, output_file_path, start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c19fc3-7d51-4e15-935f-6dc131190058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice all ERA5 files time range to match AIFS and GraphCast time range\n",
    "# Time range: 2024-XX-01T06:00:00 - 2024-XX-11T06:00:00\n",
    "# Apply the function to all monthly ERA5 files both in the Pressure Variable folder and the Surface Variable folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f3dad-1308-4f24-852f-9adfe984aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"Pressure Variables/20240301/20240301_era5_q.nc\"\n",
    "output_file_path = \"Pressure Variables/20240301/20240301_era5_gcai_q.nc\"\n",
    "start_time = \"2024-03-01T06:00:00\"\n",
    "end_time = \"2024-03-11T06:00:00\"\n",
    "filter_era5_time_range(input_file_path, output_file_path, start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d91ad37-b37f-4d88-8878-85f9e73c3780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8767b2fc-2fab-4ddb-b587-07c452cf6c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18ae5f5-00d1-4a75-ac52-bb9525b5e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the Longitude of the data files\n",
    "# Change longitude range from 0 to 360 to -180 to 180. \n",
    "# Make sure new netcdf is correctly georeferenced to same crs as the original one (crs WGS84 epsg:4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f2b90-253b-434b-8ad3-4880bb9980f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fix the longitude range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f20ab5-fbd8-407d-8243-b1263348ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_fix(input_file_path):\n",
    "\n",
    "    # Load the dataset\n",
    "    ds = xr.open_dataset(input_file_path)\n",
    "\n",
    "    try:\n",
    "    \n",
    "        # Ensure longitude and latitude are correctly assigned as coordinates\n",
    "        if \"longitude\" not in ds.coords:\n",
    "            ds = ds.assign_coords(longitude=ds[\"longitude\"])\n",
    "        if \"latitude\" not in ds.coords:\n",
    "            ds = ds.assign_coords(latitude=ds[\"latitude\"])\n",
    "\n",
    "        # Check if longitude is already in the -180 to 180 range\n",
    "        lon_min, lon_max = ds.longitude.min().item(), ds.longitude.max().item()\n",
    "        if lon_min >= -180 and lon_max <= 180:\n",
    "            print(\"Longitude is already in the correct range. No conversion needed.\")\n",
    "            ds.close()\n",
    "            return  # Exit without modifying the file\n",
    "\n",
    "        # Convert longitudes from 0-360 to -180 to 180\n",
    "        ds.coords['longitude'] = ((ds.coords['longitude'] + 180) % 360) - 180\n",
    "        ds = ds.sortby(ds.longitude)  # Sort longitudes after conversion\n",
    "        \n",
    "        # Convert longitudes from 0-360 to -180 to 180\n",
    "        ds.coords['longitude'] = ((ds.coords['longitude'] + 180) % 360) - 180\n",
    "        ds = ds.sortby(ds.longitude)  # Sort longitudes after conversion\n",
    "        \n",
    "        # Ensure CRS is assigned\n",
    "        ds.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "        \n",
    "        # Set explicit encoding (GDAL needs this - so that QGIS visualises the extent correctly)\n",
    "        ds['longitude'].attrs['standard_name'] = 'longitude'\n",
    "        ds['latitude'].attrs['standard_name'] = 'latitude'\n",
    "        ds['longitude'].attrs['units'] = 'degrees_east'\n",
    "        ds['latitude'].attrs['units'] = 'degrees_north'\n",
    "    \n",
    "        # Create a temporary file path\n",
    "        temp_file_path = input_file_path + \".tmp\"\n",
    "    \n",
    "        # Save filtered dataset to a temporary file\n",
    "        ds.to_netcdf(temp_file_path)\n",
    "\n",
    "        # Close the original file\n",
    "        ds.close()\n",
    "    \n",
    "        # Replace the original file safely\n",
    "        os.replace(temp_file_path, input_file_path)\n",
    "        \n",
    "        print(f\"Processed file saved as: {input_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e999a7-ecdc-4685-8e71-b92813029644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4cd755-3db6-4094-8a03-e6880ac41f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the longitude of all files in the Surface Variable folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873e5e4-04f5-4682-ac70-18eb300292ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base directory\n",
    "base_dir = \"Surface Variables\"\n",
    "\n",
    "# Iterate through all subfolders in \"Surface Variables\"\n",
    "for subfolder in sorted(os.listdir(base_dir)):  # Sort to process in order\n",
    "    subfolder_path = os.path.join(base_dir, subfolder)\n",
    "\n",
    "    if os.path.isdir(subfolder_path):  # Check if it's a directory\n",
    "        for file_name in os.listdir(subfolder_path):\n",
    "            if file_name.endswith(\".nc\"):\n",
    "\n",
    "                input_file_path = os.path.join(subfolder_path, file_name)\n",
    "\n",
    "                long_fix(input_file_path)\n",
    "\n",
    "                #print(input_file_path)\n",
    "\n",
    "print(\"All surface variable files have been processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ddfa17-65db-4f41-b497-1e8833a57f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the longitude of all files in the Pressure Variable folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd71d0d-9734-4a04-8669-d259f0163176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base directory\n",
    "base_dir = \"Pressure Variables\"\n",
    "\n",
    "# Iterate through all subfolders in \"Surface Variables\"\n",
    "for subfolder in sorted(os.listdir(base_dir)):  # Sort to process in order\n",
    "    subfolder_path = os.path.join(base_dir, subfolder)\n",
    "\n",
    "    if os.path.isdir(subfolder_path):  # Check if it's a directory\n",
    "        for file_name in os.listdir(subfolder_path):\n",
    "            if file_name.endswith(\".nc\"):\n",
    "\n",
    "                input_file_path = os.path.join(subfolder_path, file_name)\n",
    "\n",
    "                long_fix(input_file_path)\n",
    "\n",
    "                #print(input_file_path)\n",
    "\n",
    "print(\"All pressure variable files have been processed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
